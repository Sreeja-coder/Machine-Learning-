{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from word2number import w2n\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_split_data(filename):\n",
    "    file = open(filename, \"r\").read()\n",
    "    list_rows = []\n",
    "    file = file.split(\"\\n\")\n",
    "    for row in range(0, len(file) - 1):\n",
    "        dict_rows = {}\n",
    "        splits = file[row].split(\" \")\n",
    "        for s in range(len(splits)):\n",
    "            if s == 0:\n",
    "                if int(splits[s]) == 1:\n",
    "                    dict_rows[s] =  int(splits[0])\n",
    "                else:\n",
    "                    dict_rows[s] = -1\n",
    "            else:\n",
    "                index,val = [float(e) for e in splits[s].split(':')]\n",
    "                dict_rows[index] = val\n",
    "        list_rows.append(dict_rows)\n",
    "    df =  pd.DataFrame.from_dict(list_rows)\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glove_train = read_split_data('glove.train.libsvm')\n",
    "df_glove_test = read_split_data('glove.test.libsvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  pd.read_csv('misc-attributes-train.csv')\n",
    "eval =  pd.read_csv('misc-attributes-eval.csv')\n",
    "test = pd.read_csv('misc-attributes-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "defendants_age = []\n",
    "defendant_gender=[]\n",
    "num_victims=[]\n",
    "offence_category=[]\n",
    "offence_subcategory=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_age(x):\n",
    "    \n",
    "    for i,age in enumerate(x['defendant_age']):\n",
    "#         print(\"age\",age)\n",
    "        # print(i)\n",
    "        age = age.strip(\"(  ) -\")\n",
    "        if age != \"not known\":\n",
    "            age = age.replace(\"years\",\"\")\n",
    "            age = age.replace(\"about\", \"\")\n",
    "            age = age.replace(\"age\",\"\")\n",
    "            age = age.replace(\"of\", \"\" )\n",
    "            age = age.replace(\"old\", \"\")\n",
    "            age = age.strip()\n",
    "            if age.find(\" \") >= 0:\n",
    "                temp = age.split(\" \")\n",
    "                # print(temp)\n",
    "                age = '-'.join(temp)\n",
    "            syns = wordnet.synsets(age.strip())\n",
    "            # print(\"A\",age)\n",
    "            # print(\"S\",syns[0].lemmas()[0].name())\n",
    "            age = syns[0].lemmas()[0].name()\n",
    "            if age.find(\"-\") >= 0:\n",
    "                temp = age.split(\"-\")\n",
    "                # print(temp)\n",
    "                age = ' '.join(temp)\n",
    "            # print(age.strip())\n",
    "            defendants_age.append(w2n.word_to_num(age.strip()))\n",
    "        else:\n",
    "            defendants_age.append(int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_age(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = ['female', 'indeterminate', 'male']\n",
    "off_cat = ['breakingPeace','damage','deception','kill','miscellaneous','royalOffences','sexual','theft','violentTheft']\n",
    "off_sub_cat = ['animalTheft','arson','assault','assaultWithIntent','assaultWithSodomiticalIntent','bankrupcy','bigamy','burglary','coiningOffences',\n",
    " 'concealingABirth', 'conspiracy', 'embezzlement','extortion','forgery','fraud','gameLawOffence','grandLarceny','highwayRobbery',\n",
    " 'housebreaking','illegalAbortion','indecentAssault','infanticide','keepingABrothel','kidnapping','libel','mail','manslaughter',\n",
    " 'murder','other','perjury','pervertingJustice','pettyLarceny','pettyTreason','piracy','pocketpicking','rape','receiving',\n",
    " 'religiousOffences','returnFromTransportation','riot','robbery','seditiousLibel','seditiousWords','seducingAllegiance',\n",
    " 'shoplifting','simpleLarceny','sodomy','stealingFromMaster','taxOffences','theftFromPlace','threateningBehaviour','treason',\n",
    " 'wounding','coiningOffences','vagabond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_gender(x):\n",
    "    for i,g in enumerate(x['defendant_gender']):\n",
    "        if g in gender:\n",
    "            defendant_gender.append(gender.index(g))\n",
    "#     return defendant_gender\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_offence_category(x):\n",
    "    for i,off in enumerate(x['offence_category']):\n",
    "        if off in off_cat:\n",
    "            offence_category.append(off_cat.index(off))\n",
    "#     return offence_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_offence_subcategory(x):\n",
    "    for i,off_sub in enumerate(x['offence_subcategory']):\n",
    "        if off_sub in off_sub_cat:\n",
    "            offence_subcategory.append(off_sub_cat.index(off_sub))\n",
    "#     return offence_subcategory\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_victims = list(dataset['num_victims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(df_glove_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorize_gender(dataset)\n",
    "factorize_offence_category(dataset)\n",
    "factorize_offence_subcategory(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(labels,defendants_age,defendant_gender,num_victims,offence_category,offence_subcategory)),  columns =[\"label\",\"defendants_age\" ,\"defendants_gender\",\"num_victims\",\"offence_category\",\"offence_sub_category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numpy = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_perceptron(data,hp,ep):\n",
    "    # initialize weights and bias term randomly between -0.01 and 0.01\n",
    "    np.random.seed(7)\n",
    "    update = 0\n",
    "    av_w = np.zeros(shape=data.shape[1]-1)\n",
    "    av_b = 0\n",
    "    w = np.random.uniform(-0.01, 0.01, size=data.shape[1] - 1)\n",
    "    b = np.random.uniform(-0.01, 0.01)\n",
    "    dict_epoch_acc = {}\n",
    "    learning_rate = hp\n",
    "    for i in range(ep):\n",
    "        accuracy = 0\n",
    "        np.random.shuffle(data)\n",
    "        for r in range(len(data)):\n",
    "            ground_truth = data[r, 0]\n",
    "            sample = data[r, 1:]\n",
    "            if np.dot(np.transpose(w), sample) + b <= 0:\n",
    "                prediction = -1\n",
    "            else:\n",
    "                prediction = 1\n",
    "            if int(ground_truth) != int(prediction):\n",
    "                update += 1\n",
    "                w = w + learning_rate * ground_truth * sample\n",
    "                b = b + learning_rate * ground_truth\n",
    "            else:\n",
    "                accuracy += 1\n",
    "            av_w = av_w + w\n",
    "            av_b = av_b + b\n",
    "        dict_epoch_acc[i] = av_w, av_b, (accuracy / len(data))\n",
    "    return  dict_epoch_acc,update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(we, bi, test_data):\n",
    "    accuracy = 0\n",
    "    for r in range(len(test_data)):\n",
    "        ground_truth = test_data[r,0]\n",
    "        sample = list(test_data[r,:])\n",
    "        sample.pop(0)\n",
    "        prediction = -1 if np.dot(np.transpose(we), sample) + bi <= 0 else 1\n",
    "        if prediction == ground_truth:\n",
    "            accuracy = accuracy + 1\n",
    "    return (accuracy / len(test_data)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_max(dict):\n",
    "    acc = 0\n",
    "    we_training = []\n",
    "    bias_training = 0\n",
    "    for key, value in dict.items():\n",
    "        if acc < value[2]:\n",
    "            acc = value[2]\n",
    "            we_training = value[0]\n",
    "            bias_training = value[1]\n",
    "    return we_training,bias_training,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(f1,f2,f3,f4,f5):\n",
    "\n",
    "    best_h = 0\n",
    "    max_acc = 0\n",
    "    hyper_paramter = [0.1,1,0.01]\n",
    "    for h in hyper_paramter:\n",
    "        acc = 0\n",
    "        #run for f1 as test:\n",
    "        frames = [f2, f3, f4, f5]\n",
    "        train =np.concatenate((f2,f3,f4,f5),axis=0)\n",
    "        d, u = batch_perceptron(train, h, 10)\n",
    "        w1,b1,a1 = cal_max(d)\n",
    "        acc = acc + evaluate(w1,b1,f1)\n",
    "        #run for f2 as test\n",
    "        frames = [f1, f3, f4, f5]\n",
    "        train = np.concatenate((f1,f3,f4,f5),axis=0)\n",
    "        d, u = batch_perceptron(train, h, 10)\n",
    "        w1, b1, a1 = cal_max(d)\n",
    "        acc = acc + evaluate(w1, b1, f2)\n",
    "        #run for f3 as test\n",
    "        frames = [f2, f1, f4, f5]\n",
    "        train = np.concatenate((f1, f2, f4, f5), axis=0)\n",
    "        d, u = batch_perceptron(train, h, 10)\n",
    "        w1, b1, a1 = cal_max(d)\n",
    "        acc = acc + evaluate(w1, b1, f3)\n",
    "        #run for f4 as test\n",
    "        frames = [f2, f1, f3, f5]\n",
    "        train = np.concatenate((f1, f3, f2, f5), axis=0)\n",
    "        d, u = batch_perceptron(train, h, 10)\n",
    "        w1, b1, a1 = cal_max(d)\n",
    "        acc = acc + evaluate(w1, b1, f4)\n",
    "        #run for f5 as test\n",
    "        frames = [f2, f1, f4, f3]\n",
    "        train = np.concatenate((f1, f3, f4, f2), axis=0)\n",
    "        d, u = batch_perceptron(train, h, 10)\n",
    "        w1, b1, a1 = cal_max(d)\n",
    "        acc = acc + evaluate(w1, b1, f5)\n",
    "        if max_acc < acc/5:\n",
    "            max_acc = acc/5\n",
    "            best_h = h\n",
    "    return best_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1 = train_numpy[5000:7500,:]\n",
    "fold2 = train_numpy[7500:10000,:]\n",
    "fold3 = train_numpy[10000:12500,:]\n",
    "fold4 = train_numpy[12500:15000,:]\n",
    "fold5 = train_numpy[15000:17500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = crossvalidation(fold1,fold2,fold3,fold4,fold5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= {}\n",
    "bias = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = np.copy(train_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    np.random.shuffle(train1)\n",
    "    sample = train1[:1750,:]    \n",
    "    dict_training_per,u = batch_perceptron(sample, best_lr, 10)\n",
    "    w,b,a = cal_max(dict_training_per)\n",
    "    weights[i] = w\n",
    "    bias[i] = b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(we,b,sample):\n",
    "#     sample.pop(0)\n",
    "    prediction = -1 if np.dot(np.transpose(we), sample) + b <= 0 else 1\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_dataset(weights,bias,data):\n",
    "    l = []\n",
    "    for i in range(len(data)):\n",
    "        row = []\n",
    "        row.append(data[i,0])\n",
    "        for key,value in weights.items():\n",
    "            x = data[i,1:]\n",
    "#             del prediction_rows[:]\n",
    "            p=prediction(value,bias[key],x)\n",
    "#             p = prediction_rows[0]\n",
    "            row.append(p)\n",
    "        l.append(row)\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_dataset_eval(weights,bias,data):\n",
    "    l = []\n",
    "    for i in range(len(data)):\n",
    "        row = []\n",
    "#         row.append(data[i,0])\n",
    "        for key,value in weights.items():\n",
    "            x = data[i,:]\n",
    "#             del prediction_rows[:]\n",
    "            p=prediction(value,bias[key],x)\n",
    "#             p = prediction_rows[0]\n",
    "            row.append(p)\n",
    "        l.append(row)\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### for testing ######\n",
    "defendants_age = []\n",
    "defendant_gender=[]\n",
    "num_victims=[]\n",
    "offence_category=[]\n",
    "offence_subcategory=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_age(test)\n",
    "factorize_gender(test)\n",
    "factorize_offence_category(test)\n",
    "factorize_offence_subcategory(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_victims = list(test['num_victims'])\n",
    "label= list(df_glove_test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(list(zip(label,defendants_age,defendant_gender,num_victims,offence_category,offence_subcategory)),  columns =[\"label\",\"defendants_age\" ,\"defendants_gender\",\"num_victims\",\"offence_category\",\"offence_sub_category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numpy = df_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### for eval #######\n",
    "defendants_age = []\n",
    "defendant_gender=[]\n",
    "num_victims=[]\n",
    "offence_category=[]\n",
    "offence_subcategory=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "factorize_gender(eval)\n",
    "factorize_offence_category(eval)\n",
    "factorize_offence_subcategory(eval)\n",
    "num_victims = list(eval['num_victims'])\n",
    "label = [0 for i in range(len(eval))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,age in enumerate(eval['defendant_age']):\n",
    "#         print(\"age\",age)\n",
    "        # print(i)\n",
    "        age = age.strip(\"(  ) -\")\n",
    "        if age != \"not known\":\n",
    "            age = age.replace(\"years\",\"\")\n",
    "            age = age.replace(\"about\", \"\")\n",
    "            age = age.replace(\"age\",\"\")\n",
    "            age = age.replace(\"of\", \"\" )\n",
    "            age = age.replace(\"old\", \"\")\n",
    "            age = age.replace(\"Year\", \"\")\n",
    "            age = age.replace(\"his\", \"\")\n",
    "            age = age.replace(\"Age\", \"\")\n",
    "            age = age.strip()\n",
    "            age = age.strip(\"d\")\n",
    "            \n",
    "            if age.find(\" \") >= 0:\n",
    "                temp = age.split(\" \")\n",
    "                if \"and\" in temp or \"or\" in temp:\n",
    "                    age = temp[0]\n",
    "#                     temp.remove(\"and\")\n",
    "#                 if \"months\" in temp or \"month\" in temp:\n",
    "#                     temp.remove(\"months\")\n",
    "# #                     temp.remove(\"month\")\n",
    "                # print(temp)\n",
    "                else:\n",
    "                    age = '-'.join(temp)\n",
    "#             print(\"**\",age)\n",
    "            syns = wordnet.synsets(age.strip())\n",
    "#             print(\"syns\",syns)\n",
    "            # print(\"A\",age)\n",
    "            # print(\"S\",syns[0].lemmas()[0].name())\n",
    "            age = syns[0].lemmas()[0].name()\n",
    "            if age.find(\"-\") >= 0:\n",
    "                temp = age.split(\"-\")\n",
    "                # print(temp)\n",
    "                age = ' '.join(temp)\n",
    "#             print(age)\n",
    "#             defendants_age.append(w2n.word_to_num(age.strip()))\n",
    "            try:\n",
    "                defendants_age.append(w2n.word_to_num(age.strip()))\n",
    "            except:\n",
    "                defendants_age.append(int(0))\n",
    "        else:\n",
    "            defendants_age.append(int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(list(zip(defendants_age,defendant_gender,num_victims,offence_category,offence_subcategory)),  columns =[\"defendants_age\" ,\"defendants_gender\",\"num_victims\",\"offence_category\",\"offence_sub_category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_numpy = df_eval.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svm = new_dataset(weights,bias,train_numpy)\n",
    "test_svm = new_dataset(weights,bias,test_numpy)\n",
    "eval_svm = new_dataset_eval(weights,bias,eval_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(data,lr,C,ep):\n",
    "    #initialize weights and bias term\n",
    "\n",
    "    lr_0 = lr\n",
    "    loss = 0.0\n",
    "    dict_epoch_accuracy = {}\n",
    "    dict_epoch_loss = {}\n",
    "    prev_loss = float(\"inf\")\n",
    "    seed(7)\n",
    "    # print(data.shape[1])\n",
    "    w = np.random.uniform(-0.01,0.01,size=data.shape[1])\n",
    "    # for i in range(len(data.columns)):\n",
    "    #     w.append(uniform(-0.01,0.01))\n",
    "    # print(len(w))\n",
    "    #for epoch as per threshold\n",
    "    for i in range(ep):\n",
    "        # print(\"for epoch\",i)\n",
    "\n",
    "        lr = lr/(1+i)\n",
    "        np.random.shuffle(data)\n",
    "        # data =  data.sample(frac=1,random_state=1)\n",
    "        for row in range(len(data)):\n",
    "            y = data[row,0]\n",
    "            x = data[row,1:]\n",
    "            # x.pop(0)\n",
    "            x = np.append(x,1)\n",
    "\n",
    "            # print(\"len of x\",len(x))\n",
    "            if np.dot((np.transpose(w)),x)*y <= 1:\n",
    "                w = ((1-lr)*w) + ((lr*C*y)*x)\n",
    "            else:\n",
    "                w = (1-lr)*w\n",
    "\n",
    "        dict_epoch_accuracy[i] = i,evaluate(w,data),w\n",
    "        # print(\"accuracy\",accuracy)\n",
    "            ## calculate the loss/value of the objective function\n",
    "        # loss = (1/2)*np.dot(np.transpose(w),w)\n",
    "        # for row in range(len(data)):\n",
    "        #     y1 = data[row,0]\n",
    "        #     x1 = data[row,1:]\n",
    "        #     x1 = np.append(x1, 1)\n",
    "        #     # loss = round(loss + max(0,(1- (y1 * np.dot(np.transpose(w),x1)))),4)\n",
    "        #     loss = loss + (C*max(0, (1 - (y1 * np.dot(np.transpose(w), x1)))))\n",
    "        loss = (1/2)*np.dot(np.transpose(w),w)\n",
    "        l = 0\n",
    "        # loss = (1/2)*np.dot(np.transpose(w),w)\n",
    "        for row in range(len(data)):\n",
    "            y1 = data[row,0]\n",
    "            x1 = data[row,1:]\n",
    "            x1 = np.append(x1, 1)\n",
    "            # loss = round(loss + max(0,(1- (y1 * np.dot(np.transpose(w),x1)))),4)\n",
    "            l =  l + (max(0, (1 - (y1 * np.dot(np.transpose(w), x1)))))\n",
    "        loss = loss + C*l\n",
    "        # print(\"loss\",loss)\n",
    "        dict_epoch_loss[i] = loss\n",
    "        if abs(prev_loss - loss)  < 0.005:\n",
    "            # print(\"threshold epoch\",i)\n",
    "            break\n",
    "        prev_loss = loss\n",
    "\n",
    "    return dict_epoch_accuracy,dict_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_cross_validation(data,lr,C,ep):\n",
    "    #initialize weights and bias term\n",
    "    w = []\n",
    "    lr_0 = lr\n",
    "    loss = 0.0\n",
    "    dict_epoch_accuracy = {}\n",
    "    dict_epoch_loss = {}\n",
    "    prev_loss =  float(\"inf\")\n",
    "\n",
    "    # print(data.shape[1])\n",
    "    w = np.random.uniform(-0.01,0.01,size=data.shape[1])\n",
    "    # for i in range(len(data.columns)):\n",
    "    #     w.append(uniform(-0.01,0.01))\n",
    "    # print(len(w))\n",
    "    #for epoch as per threshold\n",
    "    for i in range(ep):\n",
    "        # print(\"for epoch\",i)\n",
    "        accuracy = 0\n",
    "        lr = lr_0/(1+i)\n",
    "        np.random.shuffle(data)\n",
    "        # data =  data.sample(frac=1,random_state=1)\n",
    "        for row in range(len(data)):\n",
    "            y = data[row,0]\n",
    "            x = data[row,1:]\n",
    "            # x.pop(0)\n",
    "            x = np.append(x,1)\n",
    "\n",
    "            # print(\"len of x\",len(x))\n",
    "            if np.dot((np.transpose(w)),x)*y <= 1:\n",
    "                w = ((1-lr)*w) + ((lr*C*y)*x)\n",
    "            else:\n",
    "                w = (1-lr)*w\n",
    "                accuracy = accuracy + 1\n",
    "        dict_epoch_accuracy[i] = i,evaluate(w,data),w\n",
    "    return dict_epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_max(d):\n",
    "    max_w = []\n",
    "    max_accuracy = -1\n",
    "    epoch = 0\n",
    "    for key, value in d.items():\n",
    "        if value[1] > max_accuracy:\n",
    "            max_accuracy = value[1]\n",
    "            max_w = value[2]\n",
    "            epoch = value[0]\n",
    "        # if max_accuracy == 0:\n",
    "    # print(len(max_w))\n",
    "    return  epoch, max_accuracy,max_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(we, test_data):\n",
    "    accuracy = 0\n",
    "    for r in range(len(test_data)):\n",
    "        y = test_data[r,0]\n",
    "        x = test_data[r,1:]\n",
    "        # sample.pop(0)\n",
    "        x = np.append(x,1)\n",
    "        # print(len(we))\n",
    "        # print(len(x))\n",
    "        prediction = -1 if np.dot(np.transpose(we), x) <= 0 else 1\n",
    "        # if np.dot((np.transpose(we)),x)*y >= 1:\n",
    "        if prediction == y:\n",
    "            accuracy = accuracy + 1\n",
    "    return (accuracy / len(test_data)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(f1,f2,f3,f4,f5):\n",
    "    lr = [10**0,10**-1,10**-2,10**-3,10**-4,10**-5]\n",
    "    C = [10**3,10**2,10**1,10**0,10**-1,10**-2]\n",
    "    best_lr=0\n",
    "    best_c = 0\n",
    "    max_acc = 0\n",
    "    for c in C:\n",
    "        for l in lr:\n",
    "            # print(\"running for learning rate:\",l,\"C:\",c)\n",
    "            acc = 0\n",
    "            # run for f1 as test:\n",
    "            # print(\"f1 as test\")\n",
    "            frames = [f2, f3, f4, f5]\n",
    "            train = np.concatenate((f2,f3,f4,f5),axis=0)\n",
    "            # print(\"len\", len(f2.columns))\n",
    "            # print(\"len\", len(f3.columns))\n",
    "            # print(\"len\", len(f4.columns))\n",
    "            # print(\"len\", len(f5.columns))\n",
    "            # train = pd.concat(frames)\n",
    "            # print(\"len\",len(train.columns))\n",
    "            # dict_acc_w= svm_cross_validation(train, l, c, 20)\n",
    "            dict_acc_w = svm_cross_validation(train, l, c, 20)\n",
    "            e,a,w = cal_max(dict_acc_w)\n",
    "            acc = acc + evaluate(w, f1)\n",
    "            # run for f2 as test\n",
    "            # print(\"f2 as test\")\n",
    "            frames = [f1, f3, f4, f5]\n",
    "            train = np.concatenate((f1,f3,f4,f5),axis=0)\n",
    "            # train = pd.concat(frames)\n",
    "            dict_acc_w= svm_cross_validation(train, l, c, 20)\n",
    "            e,a,w = cal_max(dict_acc_w)\n",
    "            acc = acc + evaluate(w ,f2)\n",
    "            # run for f3 as test\n",
    "            # print(\"f3 as test\")\n",
    "            # frames = [f2, f1, f4, f5]\n",
    "            # train = pd.concat(frames)\n",
    "            train = np.concatenate((f1, f2, f4, f5), axis=0)\n",
    "            dict_acc_w= svm_cross_validation(train, l, c, 20)\n",
    "            e,a,w = cal_max(dict_acc_w)\n",
    "            acc = acc + evaluate(w, f3)\n",
    "            # run for f4 as test\n",
    "            # print(\"f4 as test\")\n",
    "            # frames = [f2, f1, f3, f5]\n",
    "            # train = pd.concat(frames)\n",
    "            train = np.concatenate((f1, f3, f2, f5), axis=0)\n",
    "            dict_acc_w= svm_cross_validation(train, l, c, 20)\n",
    "            e,a,w = cal_max(dict_acc_w)\n",
    "            acc = acc + evaluate(w, f4)\n",
    "            # run for f5 as test\n",
    "            # print(\"f5 as test\")\n",
    "            # frames = [f2, f1, f4, f3]\n",
    "            # train = pd.concat(frames)\n",
    "            train = np.concatenate((f1, f3, f4, f2), axis=0)\n",
    "            dict_acc_w= svm_cross_validation(train, l, c, 20)\n",
    "            e,a,w = cal_max(dict_acc_w)\n",
    "            acc = acc + evaluate(w, f5)\n",
    "            acc = acc/5\n",
    "            if max_acc<acc:\n",
    "                max_acc = acc\n",
    "                best_c =c\n",
    "                best_lr = l\n",
    "    print(\"best parameters\", \"accuracy\",max_acc,\"C:\",best_c,\"lr:\",best_lr)\n",
    "            # dict_margin_lr[(m, lr)] = acc / 5\n",
    "            # print(dict_margin_lr.keys())\n",
    "    return max_acc,best_c,best_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fold1_svm = new_dataset(weights,bias,fold1)    \n",
    "    fold2_svm = new_dataset(weights,bias, fold2)\n",
    "    fold3_svm = new_dataset(weights,bias, fold3)\n",
    "    fold4_svm = new_dataset(weights,bias, fold4)\n",
    "    fold5_svm = new_dataset(weights,bias, fold5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters accuracy 78.072 C: 10 lr: 0.01\n"
     ]
    }
   ],
   "source": [
    "a,c,lr = crossvalidation(fold1_svm,fold2_svm,fold3_svm,fold4_svm,fold5_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_a_w, dict_loss = svm(train_svm, lr, c, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, a, w = cal_max(dict_a_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.12"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(w, train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.02222222222223"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(w, test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_e(we, test_data):\n",
    "    accuracy = 0\n",
    "    p = []\n",
    "    for r in range(len(test_data)):\n",
    "        \n",
    "        x = test_data[r,:]\n",
    "        # sample.pop(0)\n",
    "        x = np.append(x,1)\n",
    "        # print(len(we))\n",
    "        # print(len(x))\n",
    "        prediction = -1 if np.dot(np.transpose(we), x) <= 0 else 1\n",
    "        p.append(prediction)\n",
    "        # if np.dot((np.transpose(we)),x)*y >= 1:\n",
    "#         if prediction == y:\n",
    "#             accuracy = accuracy + 1\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= evaluate_e(w, eval_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('perceptron_svm_ensemble.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"example_id\", \"label\"])\n",
    "    for i in range(len(p)):\n",
    "        if p[i]== -1:\n",
    "            val = 0\n",
    "        else:\n",
    "            val = 1\n",
    "        writer.writerow([i, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
